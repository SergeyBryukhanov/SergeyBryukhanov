{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODFj3GjhRtDRT9WU5yY8kL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "98f2f31b71774f639839ddc2bd26b215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c0a774badbd4fd387b595e30412733d",
              "IPY_MODEL_6d1c6d4d58c648718439303baadb03e8",
              "IPY_MODEL_047e9a982c0a41ca8e892c1de31c4ecd"
            ],
            "layout": "IPY_MODEL_aaeb74309a3945eba1026aeda90e3565"
          }
        },
        "5c0a774badbd4fd387b595e30412733d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_171d476d04b24a6983090fe2fbb4db55",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad6367f8af94a7da33ce608bd19f354",
            "value": "config.json: 100%"
          }
        },
        "6d1c6d4d58c648718439303baadb03e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d5e935092b49d1bbe5a3976afcdb92",
            "max": 622,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fab045ed0074c509896d64498862485",
            "value": 622
          }
        },
        "047e9a982c0a41ca8e892c1de31c4ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b85080600f4ff59feaf5bb6e888e47",
            "placeholder": "​",
            "style": "IPY_MODEL_b961f4818ad44fb693160fcdd2c00a5f",
            "value": " 622/622 [00:00&lt;00:00, 4.48kB/s]"
          }
        },
        "aaeb74309a3945eba1026aeda90e3565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "171d476d04b24a6983090fe2fbb4db55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad6367f8af94a7da33ce608bd19f354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12d5e935092b49d1bbe5a3976afcdb92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fab045ed0074c509896d64498862485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84b85080600f4ff59feaf5bb6e888e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b961f4818ad44fb693160fcdd2c00a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2910d1b782bc49b6933eb70a282f626f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73ea9bf801934bde9ba4ce58d4473c34",
              "IPY_MODEL_37475b8862b34dedbd38b9c2046300f0",
              "IPY_MODEL_26b030f95ee94878bca77eb61834f17d"
            ],
            "layout": "IPY_MODEL_738edab859374c2f9d28a977ecd7f1ea"
          }
        },
        "73ea9bf801934bde9ba4ce58d4473c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cbdce55f037480bb2a50e2d529584ad",
            "placeholder": "​",
            "style": "IPY_MODEL_221727d5c40b4ace8c16708d22e505ee",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "37475b8862b34dedbd38b9c2046300f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc0cd28783f4b39ab7f08b692b7f7b7",
            "max": 3141928084,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a105eb71b39548dea7cec9fb6e6f72ab",
            "value": 3141928084
          }
        },
        "26b030f95ee94878bca77eb61834f17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ef21042a64455896fc8271ff2cb6e0",
            "placeholder": "​",
            "style": "IPY_MODEL_66481c5eea0e4997b60cdfa58c8591a8",
            "value": " 3.14G/3.14G [01:28&lt;00:00, 16.5MB/s]"
          }
        },
        "738edab859374c2f9d28a977ecd7f1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cbdce55f037480bb2a50e2d529584ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "221727d5c40b4ace8c16708d22e505ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fc0cd28783f4b39ab7f08b692b7f7b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a105eb71b39548dea7cec9fb6e6f72ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77ef21042a64455896fc8271ff2cb6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66481c5eea0e4997b60cdfa58c8591a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a0a269981474bf7bda2c27668209f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c976a761bf547dd9e8c8b42bb1e8434",
              "IPY_MODEL_c22718a153e8409bb33271fa0c89c8e4",
              "IPY_MODEL_67cbfc71f60e4f0abbeb72371bdd3468"
            ],
            "layout": "IPY_MODEL_33e5c15ab9c74ed8aca30a13bec1af08"
          }
        },
        "9c976a761bf547dd9e8c8b42bb1e8434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_678faae33dab49bcbc9233c68d0c5b6c",
            "placeholder": "​",
            "style": "IPY_MODEL_40975957383a4199bd54cf693d402529",
            "value": "tokenizer_config.json: "
          }
        },
        "c22718a153e8409bb33271fa0c89c8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37e6e35cd19b4e3d882459c328dd6a42",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47312aad703a4c7eb4b6b82d86d511f1",
            "value": 1
          }
        },
        "67cbfc71f60e4f0abbeb72371bdd3468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7cc4d9fa254503af9735fd42c255f7",
            "placeholder": "​",
            "style": "IPY_MODEL_222b6acb44124e30b99617697a12f604",
            "value": " 1.25k/? [00:00&lt;00:00, 66.6kB/s]"
          }
        },
        "33e5c15ab9c74ed8aca30a13bec1af08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "678faae33dab49bcbc9233c68d0c5b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40975957383a4199bd54cf693d402529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37e6e35cd19b4e3d882459c328dd6a42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "47312aad703a4c7eb4b6b82d86d511f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a7cc4d9fa254503af9735fd42c255f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222b6acb44124e30b99617697a12f604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72065568e4ac4644bdc7d9146bb90246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b9d2774524d43468ed7be0a0b2861d0",
              "IPY_MODEL_ec59b297b2384d1d9a991122d3bf4822",
              "IPY_MODEL_8f5ba8ba9eb54a1d87e0ced2bedecc8b"
            ],
            "layout": "IPY_MODEL_ce9258a1718444bbb56dea650a0cd695"
          }
        },
        "6b9d2774524d43468ed7be0a0b2861d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6861807f954b4f959dfbd104f58617b0",
            "placeholder": "​",
            "style": "IPY_MODEL_057ca7ad4f264689bdb43206397780a5",
            "value": "vocab.json: "
          }
        },
        "ec59b297b2384d1d9a991122d3bf4822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0fc73707ebc4d4ca9d4be2c715bc81e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c45b6e1c06d946f195848b56d9774b1c",
            "value": 1
          }
        },
        "8f5ba8ba9eb54a1d87e0ced2bedecc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b60cb83e0ab4a44a048ad375815acc1",
            "placeholder": "​",
            "style": "IPY_MODEL_49faf608ccd043278a68d0550c83be27",
            "value": " 1.71M/? [00:00&lt;00:00, 1.02MB/s]"
          }
        },
        "ce9258a1718444bbb56dea650a0cd695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6861807f954b4f959dfbd104f58617b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057ca7ad4f264689bdb43206397780a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0fc73707ebc4d4ca9d4be2c715bc81e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c45b6e1c06d946f195848b56d9774b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b60cb83e0ab4a44a048ad375815acc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49faf608ccd043278a68d0550c83be27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40775298d55146e49ae9b98babf07e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d61c01047e184a65bf21c98a9a0122d9",
              "IPY_MODEL_934e58c77da14c119903d6293684a703",
              "IPY_MODEL_c8e55ddfb95e4979ad8e161d9ce983e9"
            ],
            "layout": "IPY_MODEL_2f335b49f08347f8aa55330218acb778"
          }
        },
        "d61c01047e184a65bf21c98a9a0122d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f16c5dc2c13421da0745f2290e893af",
            "placeholder": "​",
            "style": "IPY_MODEL_bf8759a50ed548fca8f530a7e5ea1c1f",
            "value": "merges.txt: "
          }
        },
        "934e58c77da14c119903d6293684a703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_533ad78bf241406e95a37f0b83250b96",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a03c45420e7a4c5dbf6522b809079a26",
            "value": 1
          }
        },
        "c8e55ddfb95e4979ad8e161d9ce983e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e86fa0fb8b8545939c3467062b564267",
            "placeholder": "​",
            "style": "IPY_MODEL_707b2db82d48442297fdfcf7b853452b",
            "value": " 1.27M/? [00:00&lt;00:00, 290kB/s]"
          }
        },
        "2f335b49f08347f8aa55330218acb778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f16c5dc2c13421da0745f2290e893af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8759a50ed548fca8f530a7e5ea1c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "533ad78bf241406e95a37f0b83250b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a03c45420e7a4c5dbf6522b809079a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e86fa0fb8b8545939c3467062b564267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707b2db82d48442297fdfcf7b853452b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b451d085c3742e6a05f6b56d0265a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c286839777a4364a5c61332eccaa72a",
              "IPY_MODEL_1e891bb28cb74882818ec2e1cd0d4821",
              "IPY_MODEL_d3bbb3c6619641f982aade134b40d3b4"
            ],
            "layout": "IPY_MODEL_432233469f9e4d0398e82fb6917c1660"
          }
        },
        "3c286839777a4364a5c61332eccaa72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b071cdb0c38a4c0990270a51ae45616b",
            "placeholder": "​",
            "style": "IPY_MODEL_8efb2e6f01a847f1bc884d784aff6335",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1e891bb28cb74882818ec2e1cd0d4821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674e54f5ab3e4b6aa063b3636a34301e",
            "max": 574,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52f87c351499493a9940238d24552978",
            "value": 574
          }
        },
        "d3bbb3c6619641f982aade134b40d3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_309d61feac244656ae0d5cce277caf23",
            "placeholder": "​",
            "style": "IPY_MODEL_d7e7ec1d46134aab8681296fb2509486",
            "value": " 574/574 [00:00&lt;00:00, 46.6kB/s]"
          }
        },
        "432233469f9e4d0398e82fb6917c1660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b071cdb0c38a4c0990270a51ae45616b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efb2e6f01a847f1bc884d784aff6335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "674e54f5ab3e4b6aa063b3636a34301e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f87c351499493a9940238d24552978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "309d61feac244656ae0d5cce277caf23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e7ec1d46134aab8681296fb2509486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeyBryukhanov/SergeyBryukhanov/blob/main/gradio_interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Интерфейс Gradio для модели от SberDevice. В качестве данных - статья из википедии по шахматам."
      ],
      "metadata": {
        "id": "Aq-aElQ1-ZgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "transformers>=4.42.0\n",
        "llama_index==0.10.46\n",
        "pyvis==0.3.2\n",
        "Ipython==7.34.0\n",
        "langchain==0.2.5\n",
        "pypdf==4.2.0\n",
        "sentencepiece==0.1.99\n",
        "accelerate==0.31.0\n",
        "bitsandbytes==0.43.1\n",
        "peft==0.11.1\n",
        "llama-index-readers-wikipedia==0.1.4\n",
        "wikipedia==1.4.0\n",
        "\n",
        "# Зависимости\n",
        "huggingface-hub==0.23.3\n",
        "torch>=2.3.1\n",
        "numpy==1.26\n",
        "packaging==24.2\n",
        "pyyaml==6.0.1\n",
        "requests==2.32.3\n",
        "tqdm==4.66.4\n",
        "filelock==3.14.0\n",
        "regex==2024.5.15\n",
        "typing-extensions==4.14\n",
        "safetensors==0.4.3\n",
        "tokenizers==0.19.1\n",
        "gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VFU1KW1_DMl",
        "outputId": "6b12af1e-8bae-4011-92e4-ebe504e8edf2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "6bu753cQ7pcL",
        "outputId": "40735a0e-44e0-43cb-b9a1-affb23dff689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.42.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.53.2)\n",
            "Collecting llama_index==0.10.46 (from -r requirements.txt (line 2))\n",
            "  Downloading llama_index-0.10.46-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyvis==0.3.2 (from -r requirements.txt (line 3))\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: Ipython==7.34.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (7.34.0)\n",
            "Collecting langchain==0.2.5 (from -r requirements.txt (line 5))\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pypdf==4.2.0 (from -r requirements.txt (line 6))\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting sentencepiece==0.1.99 (from -r requirements.txt (line 7))\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting accelerate==0.31.0 (from -r requirements.txt (line 8))\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes==0.43.1 (from -r requirements.txt (line 9))\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting peft==0.11.1 (from -r requirements.txt (line 10))\n",
            "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-readers-wikipedia==0.1.4 (from -r requirements.txt (line 11))\n",
            "  Downloading llama_index_readers_wikipedia-0.1.4-py3-none-any.whl.metadata (625 bytes)\n",
            "Collecting wikipedia==1.4.0 (from -r requirements.txt (line 12))\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub==0.23.3 (from -r requirements.txt (line 15))\n",
            "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torch>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.6.0+cu124)\n",
            "Collecting numpy==1.26 (from -r requirements.txt (line 17))\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==24.2 (from -r requirements.txt (line 18))\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pyyaml==6.0.1 (from -r requirements.txt (line 19))\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (2.32.3)\n",
            "Collecting tqdm==4.66.4 (from -r requirements.txt (line 21))\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock==3.14.0 (from -r requirements.txt (line 22))\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting regex==2024.5.15 (from -r requirements.txt (line 23))\n",
            "  Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions==4.14 (from -r requirements.txt (line 24))\n",
            "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting safetensors==0.4.3 (from -r requirements.txt (line 25))\n",
            "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tokenizers==0.19.1 (from -r requirements.txt (line 26))\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (5.37.0)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core==0.10.46 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_core-0.10.46-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis==0.3.2->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis==0.3.2->-r requirements.txt (line 3)) (4.1.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis==0.3.2->-r requirements.txt (line 3)) (3.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from Ipython==7.34.0->-r requirements.txt (line 4))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from Ipython==7.34.0->-r requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5->-r requirements.txt (line 5)) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5->-r requirements.txt (line 5)) (3.11.15)\n",
            "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain==0.2.5->-r requirements.txt (line 5))\n",
            "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.5->-r requirements.txt (line 5))\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.5->-r requirements.txt (line 5))\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5->-r requirements.txt (line 5)) (2.11.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5->-r requirements.txt (line 5)) (8.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia==1.4.0->-r requirements.txt (line 12)) (4.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3->-r requirements.txt (line 15)) (2025.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 20)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 20)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 20)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->-r requirements.txt (line 20)) (2025.7.14)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (0.28.1)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (1.97.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (11.2.1)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.5->-r requirements.txt (line 5))\n",
            "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (0.9.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (1.17.2)\n",
            "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers>=4.42.0 (from -r requirements.txt (line 1))\n",
            "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.52.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.1->-r requirements.txt (line 16)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.1->-r requirements.txt (line 16)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.1->-r requirements.txt (line 16)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.1->-r requirements.txt (line 16))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.1->-r requirements.txt (line 16)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.1->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.1->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.4 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (1.10.4)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.1.2)\n",
            "INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.38.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.11.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.11.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.36.2-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.35.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.34.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.10.3 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.10.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.34.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.34.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.33.2-py3-none-any.whl.metadata (16 kB)\n",
            "INFO: pip is still looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading gradio-5.33.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.33.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.10.2 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.32.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.10.1 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.30.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.29.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.28.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.27.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.9.1 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.26.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.25.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.25.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.24.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.23.2-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.23.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.21.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.19.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.18.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.17.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.7.1 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.17.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.16.2-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.16.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.14.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.13.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.6.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.13.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.5.4 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.11.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.5.3 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.5.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.10.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.9.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.5.1 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.7.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.5.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.7.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading gradio-5.3.0-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting gradio-client==1.4.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 27))\n",
            "  Downloading gradio-5.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading gradio-5.0.1-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading gradio-5.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (6.5.2)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (3.11.0)\n",
            "Collecting pillow>=9.0.0 (from llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.12.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (2.10.0)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 27))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 27)) (0.35.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio->-r requirements.txt (line 27))\n",
            "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5->-r requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5->-r requirements.txt (line 5)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5->-r requirements.txt (line 5)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5->-r requirements.txt (line 5)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5->-r requirements.txt (line 5)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5->-r requirements.txt (line 5)) (1.20.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 27)) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0,>=0.115.2->gradio->-r requirements.txt (line 27)) (0.47.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->Ipython==7.34.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain==0.2.5->-r requirements.txt (line 5)) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.5->-r requirements.txt (line 5)) (1.0.0)\n",
            "INFO: pip is looking at multiple versions of llama-index-llms-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_llms_openai-0.1.30-py3-none-any.whl.metadata (650 bytes)\n",
            "  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n",
            "  Downloading llama_index_llms_openai-0.1.28-py3-none-any.whl.metadata (650 bytes)\n",
            "  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n",
            "  Downloading llama_index_llms_openai-0.1.26-py3-none-any.whl.metadata (610 bytes)\n",
            "INFO: pip is looking at multiple versions of llama-index-program-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia==1.4.0->-r requirements.txt (line 12)) (2.7)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.51-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 27)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 27)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 27)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 27)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 27)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 27)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->Ipython==7.34.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython==7.34.0->-r requirements.txt (line 4)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.5->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.5->-r requirements.txt (line 5)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.5->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.5->-r requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 27)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 27)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 27)) (13.9.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain==0.2.5->-r requirements.txt (line 5)) (3.0.0)\n",
            "Collecting llama-cloud-services>=0.6.51 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.51-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (1.5.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirements.txt (line 27)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 27)) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.46->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting llama-cloud==0.1.34 (from llama-cloud-services>=0.6.51->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.34-py3-none-any.whl.metadata (1.2 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.50-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.49 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.50-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.49-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.49-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.48-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.48 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.48-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.47-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.47 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.47-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud==0.1.33 (from llama-cloud-services>=0.6.47->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.33-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.46-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.45 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.46-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.45-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.45-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.44-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.44 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.44-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.43-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.43 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.43-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud==0.1.32 (from llama-cloud-services>=0.6.43->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.32-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.42-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.42 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.42-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.41-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.41 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.41-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud==0.1.30 (from llama-cloud-services>=0.6.41->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.30-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.40-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.40 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.40-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.39-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.39 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.38-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud==0.1.29 (from llama-cloud-services>=0.6.37->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.29-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.36 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-cloud==0.1.28 (from llama-cloud-services>=0.6.36->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.28-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.35 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud==0.1.27 (from llama-cloud-services>=0.6.35->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.27-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud==0.1.26 (from llama-cloud-services>=0.6.32->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.33-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.32-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.33-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.32-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.31-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.31 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.31-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.30-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.30 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.30-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud==0.1.23 (from llama-cloud-services>=0.6.30->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.23-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.28-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.28 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.29-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.28-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.27-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.27 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.27-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.26-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.26 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.26-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.25-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.24 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.25-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.24-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.24-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.6.23-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.23 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.23-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud==0.1.22 (from llama-cloud-services>=0.6.23->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.22-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.22 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-cloud==0.1.19 (from llama-cloud-services>=0.6.22->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.20-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.20 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.20-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.18-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.17 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.19-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.18-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.17-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.16-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.16 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.16-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.12-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.12 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.15-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.14-py3-none-any.whl.metadata (3.4 kB)\n",
            "  Downloading llama_cloud_services-0.6.12-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.9-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.9 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.11-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.10-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading llama_cloud_services-0.6.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.3 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.3-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.2 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.1 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting llama-cloud-services (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index==0.10.46->-r requirements.txt (line 2))\n",
            "  Downloading llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.16-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.15-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.9-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading llama_parse-0.5.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
            "  Downloading llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n",
            "  Downloading llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "  Downloading llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 27)) (0.1.2)\n",
            "Downloading llama_index-0.10.46-py3-none-any.whl (6.8 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_wikipedia-0.1.4-py3-none-any.whl (2.3 kB)\n",
            "Downloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.10.46-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.1.26-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=9c1b3a1122be62c55679437df1b51986f0d25306ecf4507429ed5f2b7a234e95\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: striprtf, sentencepiece, dirtyjson, websockets, typing-extensions, tqdm, tomlkit, tenacity, safetensors, regex, pyyaml, pypdf, pillow, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mypy-extensions, markupsafe, jedi, filelock, deprecated, aiofiles, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, huggingface-hub, wikipedia, tokenizers, pyvis, nvidia-cusolver-cu12, dataclasses-json, transformers, llamaindex-py-client, langsmith, gradio-client, llama-index-legacy, llama-index-core, langchain-core, gradio, bitsandbytes, accelerate, peft, llama-parse, llama-index-readers-wikipedia, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.3\n",
            "    Uninstalling tomlkit-0.13.3:\n",
            "      Successfully uninstalled tomlkit-0.13.3\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.5.0\n",
            "    Uninstalling tenacity-8.5.0:\n",
            "      Successfully uninstalled tenacity-8.5.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.3\n",
            "    Uninstalling safetensors-0.5.3:\n",
            "      Successfully uninstalled safetensors-0.5.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.4\n",
            "    Uninstalling huggingface-hub-0.33.4:\n",
            "      Successfully uninstalled huggingface-hub-0.33.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.2\n",
            "    Uninstalling transformers-4.53.2:\n",
            "      Successfully uninstalled transformers-4.53.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.7\n",
            "    Uninstalling langsmith-0.4.7:\n",
            "      Successfully uninstalled langsmith-0.4.7\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.10.4\n",
            "    Uninstalling gradio_client-1.10.4:\n",
            "      Successfully uninstalled gradio_client-1.10.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.69\n",
            "    Uninstalling langchain-core-0.3.69:\n",
            "      Successfully uninstalled langchain-core-0.3.69\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.37.0\n",
            "    Uninstalling gradio-5.37.0:\n",
            "      Successfully uninstalled gradio-5.37.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.9.0\n",
            "    Uninstalling accelerate-1.9.0:\n",
            "      Successfully uninstalled accelerate-1.9.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.16.0\n",
            "    Uninstalling peft-0.16.0:\n",
            "      Successfully uninstalled peft-0.16.0\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.8\n",
            "    Uninstalling langchain-text-splitters-0.3.8:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.26\n",
            "    Uninstalling langchain-0.3.26:\n",
            "      Successfully uninstalled langchain-0.3.26\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n",
            "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\n",
            "google-genai 1.26.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\n",
            "diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\n",
            "dataproc-spark-connect 0.8.2 requires tqdm>=4.67, but you have tqdm 4.66.4 which is incompatible.\n",
            "dataproc-spark-connect 0.8.2 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0 aiofiles-23.2.1 bitsandbytes-0.43.1 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filelock-3.14.0 gradio-4.44.1 gradio-client-1.3.0 huggingface-hub-0.23.3 jedi-0.19.2 langchain-0.2.5 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.147 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.46 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.1.26 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-index-readers-wikipedia-0.1.4 llama-parse-0.4.9 llama_index-0.10.46 llamaindex-py-client-0.1.19 markupsafe-2.1.5 marshmallow-3.26.1 mypy-extensions-1.1.0 numpy-1.26.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-24.2 peft-0.11.1 pillow-10.4.0 pypdf-4.2.0 pyvis-0.3.2 pyyaml-6.0.1 regex-2024.5.15 safetensors-0.4.3 sentencepiece-0.1.99 striprtf-0.0.26 tenacity-8.3.0 tokenizers-0.19.1 tomlkit-0.12.0 tqdm-4.66.4 transformers-4.44.2 typing-extensions-4.14.0 typing-inspect-0.9.0 websockets-12.0 wikipedia-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "filelock",
                  "huggingface_hub",
                  "numpy",
                  "packaging",
                  "tqdm"
                ]
              },
              "id": "5c0e35548cd7433eaf55d12a4cabc4b3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "HF_TOKEN = getpass(\"Введите ваш токен Hugging Face: \")\n",
        "login(token=HF_TOKEN, add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDHKbvLM9Qoi",
        "outputId": "185f9f38-17a8-4ce9-bcd9-d15e0249e2e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите ваш токен Hugging Face: ··········\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "# Задаем имя модели\n",
        "MODEL_NAME = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
        "\n",
        "# Загружаем LoRA модель\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Переводим модель в режим инференса\n",
        "model.eval()\n",
        "\n",
        "# Загружаем токенизатор\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "98f2f31b71774f639839ddc2bd26b215",
            "5c0a774badbd4fd387b595e30412733d",
            "6d1c6d4d58c648718439303baadb03e8",
            "047e9a982c0a41ca8e892c1de31c4ecd",
            "aaeb74309a3945eba1026aeda90e3565",
            "171d476d04b24a6983090fe2fbb4db55",
            "0ad6367f8af94a7da33ce608bd19f354",
            "12d5e935092b49d1bbe5a3976afcdb92",
            "6fab045ed0074c509896d64498862485",
            "84b85080600f4ff59feaf5bb6e888e47",
            "b961f4818ad44fb693160fcdd2c00a5f",
            "2910d1b782bc49b6933eb70a282f626f",
            "73ea9bf801934bde9ba4ce58d4473c34",
            "37475b8862b34dedbd38b9c2046300f0",
            "26b030f95ee94878bca77eb61834f17d",
            "738edab859374c2f9d28a977ecd7f1ea",
            "8cbdce55f037480bb2a50e2d529584ad",
            "221727d5c40b4ace8c16708d22e505ee",
            "2fc0cd28783f4b39ab7f08b692b7f7b7",
            "a105eb71b39548dea7cec9fb6e6f72ab",
            "77ef21042a64455896fc8271ff2cb6e0",
            "66481c5eea0e4997b60cdfa58c8591a8",
            "9a0a269981474bf7bda2c27668209f55",
            "9c976a761bf547dd9e8c8b42bb1e8434",
            "c22718a153e8409bb33271fa0c89c8e4",
            "67cbfc71f60e4f0abbeb72371bdd3468",
            "33e5c15ab9c74ed8aca30a13bec1af08",
            "678faae33dab49bcbc9233c68d0c5b6c",
            "40975957383a4199bd54cf693d402529",
            "37e6e35cd19b4e3d882459c328dd6a42",
            "47312aad703a4c7eb4b6b82d86d511f1",
            "8a7cc4d9fa254503af9735fd42c255f7",
            "222b6acb44124e30b99617697a12f604",
            "72065568e4ac4644bdc7d9146bb90246",
            "6b9d2774524d43468ed7be0a0b2861d0",
            "ec59b297b2384d1d9a991122d3bf4822",
            "8f5ba8ba9eb54a1d87e0ced2bedecc8b",
            "ce9258a1718444bbb56dea650a0cd695",
            "6861807f954b4f959dfbd104f58617b0",
            "057ca7ad4f264689bdb43206397780a5",
            "f0fc73707ebc4d4ca9d4be2c715bc81e",
            "c45b6e1c06d946f195848b56d9774b1c",
            "4b60cb83e0ab4a44a048ad375815acc1",
            "49faf608ccd043278a68d0550c83be27",
            "40775298d55146e49ae9b98babf07e44",
            "d61c01047e184a65bf21c98a9a0122d9",
            "934e58c77da14c119903d6293684a703",
            "c8e55ddfb95e4979ad8e161d9ce983e9",
            "2f335b49f08347f8aa55330218acb778",
            "1f16c5dc2c13421da0745f2290e893af",
            "bf8759a50ed548fca8f530a7e5ea1c1f",
            "533ad78bf241406e95a37f0b83250b96",
            "a03c45420e7a4c5dbf6522b809079a26",
            "e86fa0fb8b8545939c3467062b564267",
            "707b2db82d48442297fdfcf7b853452b",
            "9b451d085c3742e6a05f6b56d0265a9e",
            "3c286839777a4364a5c61332eccaa72a",
            "1e891bb28cb74882818ec2e1cd0d4821",
            "d3bbb3c6619641f982aade134b40d3b4",
            "432233469f9e4d0398e82fb6917c1660",
            "b071cdb0c38a4c0990270a51ae45616b",
            "8efb2e6f01a847f1bc884d784aff6335",
            "674e54f5ab3e4b6aa063b3636a34301e",
            "52f87c351499493a9940238d24552978",
            "309d61feac244656ae0d5cce277caf23",
            "d7e7ec1d46134aab8681296fb2509486"
          ]
        },
        "collapsed": true,
        "id": "FBUGMiGu9Hb1",
        "outputId": "cdc42ee6-0119-4ca2-f22a-1a3aa2d3c650"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98f2f31b71774f639839ddc2bd26b215"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/3.14G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2910d1b782bc49b6933eb70a282f626f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a0a269981474bf7bda2c27668209f55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72065568e4ac4644bdc7d9146bb90246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40775298d55146e49ae9b98babf07e44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b451d085c3742e6a05f6b56d0265a9e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "\n",
        "\n",
        "def process_question(article, question):\n",
        "    # Формируем промпт для модели\n",
        "    max_input_length = 2000  # Максимальная длина входного текста (включая промпт и вопрос)\n",
        "    truncated_article = article[:max_input_length - 200]  # Оставляем место для промпта и вопроса\n",
        "    prompt = f\"Статья: {truncated_article}\\n\\nВопрос: {question}\\n\\nОтвет:\"\n",
        "\n",
        "    # Генерация ответа\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,  # Ограничиваем длину ответа\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.8,  # Управляет случайностью ответа\n",
        "        top_p=0.9,  # Управляет разнообразием\n",
        "    )\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def load_wikipedia_article():\n",
        "    # Инициализация объекта WikipediaReader\n",
        "    reader = WikipediaReader()\n",
        "\n",
        "    # Загрузка данных из википедии\n",
        "    articles = reader.load_data(\n",
        "        pages=[\"Шахматы\"],  # запрос раздела на тему шахмат\n",
        "        lang_prefix='ru'     # из русскоязычной зоны википедии\n",
        "    )\n",
        "\n",
        "    # Извлечение текста из первого документа\n",
        "    if articles and len(articles) > 0:\n",
        "        return articles[0].text  # Предполагаем, что текст статьи находится в атрибуте .text\n",
        "    else:\n",
        "        return \"Статья не найдена.\""
      ],
      "metadata": {
        "id": "5fCy_Ag49hNK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "# Создаём интерфейс Gradio\n",
        "def gradio_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "        # Поле для отображения статьи\n",
        "        article_input = gr.Textbox(label=\"Статья из Википедии\", lines=10, interactive=False)\n",
        "\n",
        "        # Кнопка для загрузки статьи\n",
        "        load_button = gr.Button(\"Распарсить данные\")\n",
        "\n",
        "        # Поле для ввода вопроса\n",
        "        question_input = gr.Textbox(label=\"Отправить запрос\", placeholder=\"Введите ваш вопрос...\")\n",
        "\n",
        "        # Кнопка для отправки запроса\n",
        "        submit_button = gr.Button(\"Отправить запрос\")\n",
        "\n",
        "        # Поле для вывода результата\n",
        "        output = gr.Textbox(label=\"Ответ модели\", lines=10)\n",
        "\n",
        "        # Обработка нажатия кнопки \"Распарсить данные\"\n",
        "        load_button.click(fn=load_wikipedia_article, outputs=article_input)\n",
        "\n",
        "        # Обработка нажатия кнопки \"Отправить запрос\"\n",
        "        submit_button.click(fn=process_question, inputs=[article_input, question_input], outputs=output)\n",
        "\n",
        "    # Запуск интерфейса\n",
        "    demo.launch()\n",
        "\n",
        "# Запускаем интерфейс\n",
        "gradio_interface()\n",
        "\n",
        "# Вопрос для модели: что такое шахматы?\n",
        "# Запрос выполняется 1-2 минуты"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "tIFtpc4Z__Fa",
        "outputId": "38b81a43-23b8-4685-97d7-771f91fe9c1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://6c7446f30930a8f058.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6c7446f30930a8f058.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ecRUW-JHwHO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}